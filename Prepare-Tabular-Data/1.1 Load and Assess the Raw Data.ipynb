{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c44e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7cf276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use the sample exploration config file to define a YAML configuration (config) file\n",
    "path_to_yaml = os.path.join(os.getcwd(),'data_exploration_config.yml')\n",
    "try:\n",
    "    with open (path_to_yaml, 'r') as c_file:\n",
    "        config = yaml.safe_load(c_file)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c715bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Add the code to your Jupyter notebook to ingest the config file you defined in the previous step \n",
    "# and create Python variables for the parameters you defined in the config file\n",
    "load_from_scratch = config['general']['load_from_scratch']\n",
    "save_raw_dataframe = config['general']['save_raw_dataframe']\n",
    "save_transformed_dataframe = config['general']['save_transformed_dataframe']\n",
    "remove_bad_values = config['general']['remove_bad_values']\n",
    "categorical = config['columns']['categorical']\n",
    "continuous = config['columns']['continuous']\n",
    "date = config['columns']['date']\n",
    "text = config['columns']['text']\n",
    "excluded = config['columns']['excluded']\n",
    "max_lat = config['bounding_box']['max_lat']\n",
    "min_long = config['bounding_box']['min_long']\n",
    "min_lat = config['bounding_box']['min_lat']\n",
    "max_lat = config['newark_bounding_box']['max_lat']\n",
    "min_long = config['newark_bounding_box']['min_long']\n",
    "min_lat = config['newark_bounding_box']['min_lat']\n",
    "geo_columns = config['geo_columns']\n",
    "input_csv = config['file_names']['input_csv']\n",
    "pickled_input_dataframe = config['file_names']['pickled_input_dataframe']\n",
    "pickled_output_dataframe = config['file_names']['pickled_output_dataframe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027388a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load the Airbnb dataset into a pandas DataFrame\n",
    "df = pd.read_csv(input_csv,parse_dates=[','.join(date)],dtype={key: 'category' for key in categorical})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ce5e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
      "Continuous columns: ['minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'latitude', 'longitude', 'price', 'id']\n",
      "Text columns: ['name', 'host_name']\n"
     ]
    }
   ],
   "source": [
    "# 5. Examine the DataFrame and determine which of the columns belong in one of the following categories\n",
    "print('Categorical columns:',str(categorical))\n",
    "print('Continuous columns:',str(continuous+excluded))\n",
    "print('Text columns:',str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47d9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                    16\n",
       "host_name               21\n",
       "last_review          10052\n",
       "reviews_per_month    10052\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Complete a basic assessment of the dataset\n",
    "# missing values\n",
    "count_missing = (len(df) - df.count())\n",
    "count_missing[count_missing != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf33a1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minimum_nights                  min    1.000000e+00\n",
       "                                max    1.250000e+03\n",
       "number_of_reviews               min    0.000000e+00\n",
       "                                max    6.290000e+02\n",
       "reviews_per_month               min    1.000000e-02\n",
       "                                max    5.850000e+01\n",
       "calculated_host_listings_count  min    1.000000e+00\n",
       "                                max    3.270000e+02\n",
       "latitude                        min    4.049979e+01\n",
       "                                max    4.091306e+01\n",
       "longitude                       min   -7.424442e+01\n",
       "                                max   -7.371299e+01\n",
       "price                           min    0.000000e+00\n",
       "                                max    1.000000e+04\n",
       "id                              min    2.539000e+03\n",
       "                                max    3.648724e+07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invalid values\n",
    "# Continuous columns should be integers instead of floats except latitude and longitude\n",
    "df[continuous+excluded].agg(['min','max']).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5188003e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neighbourhood_group': 5, 'neighbourhood': 221, 'room_type': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of distinct values in each of the categorical columns\n",
    "{category: df[category].nunique() for category in categorical}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b6d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save the DataFrame to a pickle file\n",
    "df.to_pickle(pickled_output_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
